{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from data.ETFsZZR import ETFsZZR\n",
    "from loss_functions.SharpeLoss import SharpeLoss\n",
    "from models.TGNNPO import TGNNPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device('cpu')\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "num_timesteps_in = 50\n",
    "num_timesteps_out = 1\n",
    "learning_rate = 1e-3\n",
    "lossfn = SharpeLoss()\n",
    "\n",
    "# load etfs dataset\n",
    "loader = ETFsZZR()\n",
    "dataset = loader.get_dataset(num_timesteps_in=num_timesteps_in, num_timesteps_out=num_timesteps_out)\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = np.array(train_dataset.features)\n",
    "train_target = np.array(train_dataset.targets)\n",
    "train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(device)\n",
    "train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(device)\n",
    "train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "test_input = np.array(test_dataset.features)\n",
    "test_target = np.array(test_dataset.targets)\n",
    "test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor).to(device)\n",
    "test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(device)\n",
    "test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=False, drop_last=drop_last)\n",
    "\n",
    "# static graph\n",
    "static_edge_index = next(iter(train_dataset)).edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, sharpe (loss): 0.18241: 100%|██████████| 303/303 [00:05<00:00, 55.94it/s]\n",
      "Epoch: 1, sharpe (loss): 0.10664: 100%|██████████| 303/303 [00:05<00:00, 56.92it/s]\n",
      "Epoch: 2, sharpe (loss): 0.10230: 100%|██████████| 303/303 [00:05<00:00, 55.53it/s]\n",
      "Epoch: 3, sharpe (loss): 0.12822: 100%|██████████| 303/303 [00:05<00:00, 55.21it/s]\n",
      "Epoch: 4, sharpe (loss): 0.18451: 100%|██████████| 303/303 [00:05<00:00, 55.47it/s]\n",
      "Epoch: 5, sharpe (loss): 0.23872: 100%|██████████| 303/303 [00:06<00:00, 50.49it/s] \n",
      "Epoch: 6, sharpe (loss): 0.26838: 100%|██████████| 303/303 [00:05<00:00, 57.76it/s]\n",
      "Epoch: 7, sharpe (loss): 0.15488: 100%|██████████| 303/303 [00:05<00:00, 57.76it/s]\n",
      "Epoch: 8, sharpe (loss): 0.19523: 100%|██████████| 303/303 [00:05<00:00, 55.95it/s]\n",
      "Epoch: 9, sharpe (loss): 0.17858: 100%|██████████| 303/303 [00:05<00:00, 58.61it/s]\n",
      "Epoch: 10, sharpe (loss): 0.18720: 100%|██████████| 303/303 [00:04<00:00, 60.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# define model and optimizer\n",
    "model = TGNNPO(node_features=2, periods=12, batch_size=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs + 1): \n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for steps, (X_batch, y_batch) in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict portfolio weights\n",
    "        weights_pred = model(X_batch, static_edge_index)\n",
    "  \n",
    "        # sharpe ratio loss\n",
    "        loss = lossfn(y_batch, weights_pred, ascent=True)\n",
    "        pbar.set_description(\"Epoch: %d, sharpe (loss): %1.5f\" % (epoch, loss.item() * -1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: sharpe (loss): 0.03371: 100%|██████████| 131/131 [00:02<00:00, 48.90it/s] \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loss = 0\n",
    "step = 0\n",
    "\n",
    "# Store for analysis\n",
    "weights = []\n",
    "prices = []\n",
    "\n",
    "pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "for steps, (X_batch, y_batch) in pbar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # predict portfolio weights\n",
    "    weights_pred = model(X_batch, static_edge_index)\n",
    "\n",
    "    # sharpe ratio loss\n",
    "    loss = lossfn(y_batch, weights_pred, ascent=True)\n",
    "    pbar.set_description(\"Test: sharpe (loss): %1.5f\" % (loss.item() * -1))\n",
    "\n",
    "    # store predictions and true values\n",
    "    prices.append(y_batch)\n",
    "    weights.append(weights_pred)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-popt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
