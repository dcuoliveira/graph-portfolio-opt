{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from data.ETFsZZR import ETFsZZR\n",
    "from loss_functions.SharpeLoss import SharpeLoss\n",
    "from models.TGNNPO import TGNNPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network hyperparameters\n",
    "node_features = 2\n",
    "periods = 12\n",
    "nn_batch_size = 2\n",
    "\n",
    "# optimization hyperparameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# training hyperparameters\n",
    "device = torch.device('cpu')\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "num_timesteps_in = 50\n",
    "num_timesteps_out = 1\n",
    "train_ratio = 0.7\n",
    "\n",
    "# load ant prepare dataset\n",
    "loader = ETFsZZR()\n",
    "dataset = loader.get_dataset(num_timesteps_in=num_timesteps_in, num_timesteps_out=num_timesteps_out)\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
    "\n",
    "# create train dataloaders\n",
    "train_input = np.array(train_dataset.features)\n",
    "train_target = np.array(train_dataset.targets)\n",
    "train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(device)\n",
    "train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(device)\n",
    "train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_new, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "# create test dataloaders\n",
    "test_input = np.array(test_dataset.features)\n",
    "test_target = np.array(test_dataset.targets)\n",
    "test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor).to(device)\n",
    "test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(device)\n",
    "test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=False, drop_last=drop_last)\n",
    "\n",
    "# create graph object - assume static graph\n",
    "static_edge_index = next(iter(train_dataset)).edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, sharpe (loss): 0.22167: 100%|██████████| 307/307 [00:05<00:00, 57.14it/s] \n",
      "Epoch: 1, sharpe (loss): 0.21894: 100%|██████████| 307/307 [00:05<00:00, 59.62it/s] \n",
      "Epoch: 2, sharpe (loss): 0.23057: 100%|██████████| 307/307 [00:05<00:00, 59.78it/s]\n",
      "Epoch: 3, sharpe (loss): 0.19454: 100%|██████████| 307/307 [00:05<00:00, 57.83it/s]\n",
      "Epoch: 4, sharpe (loss): 0.12337: 100%|██████████| 307/307 [00:05<00:00, 57.67it/s] \n",
      "Epoch: 5, sharpe (loss): 0.17097: 100%|██████████| 307/307 [00:06<00:00, 50.26it/s]\n",
      "Epoch: 6, sharpe (loss): 0.18500: 100%|██████████| 307/307 [00:05<00:00, 54.16it/s]\n",
      "Epoch: 7, sharpe (loss): 0.26785: 100%|██████████| 307/307 [00:05<00:00, 56.57it/s] \n",
      "Epoch: 8, sharpe (loss): 0.19831: 100%|██████████| 307/307 [00:05<00:00, 59.85it/s]\n",
      "Epoch: 9, sharpe (loss): 0.18768: 100%|██████████| 307/307 [00:05<00:00, 58.85it/s]\n",
      "Epoch: 10, sharpe (loss): 0.23595: 100%|██████████| 307/307 [00:05<00:00, 58.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# (1) model\n",
    "model = TGNNPO(node_features=node_features, periods=periods, batch_size=nn_batch_size).to(device)\n",
    "\n",
    "# (2) loss function\n",
    "lossfn = SharpeLoss()\n",
    "\n",
    "# (3) optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# (4) training procedure\n",
    "model.train()\n",
    "for epoch in range(epochs + 1): \n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for steps, (X_batch, prices_batch) in pbar:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict portfolio weights\n",
    "        weights_pred = model(X_batch, static_edge_index)\n",
    "  \n",
    "        # sharpe ratio loss\n",
    "        loss = lossfn(prices_batch, weights_pred, ascent=True)\n",
    "        pbar.set_description(\"Epoch: %d, sharpe (loss): %1.5f\" % (epoch, loss.item() * -1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: sharpe (loss): 0.03371: 100%|██████████| 131/131 [00:02<00:00, 48.91it/s] \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Store for analysis\n",
    "weights = []\n",
    "prices = []\n",
    "\n",
    "pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "for steps, (X_batch, prices_batch) in pbar:\n",
    "\n",
    "    # predict portfolio weights\n",
    "    weights_pred = model(X_batch, static_edge_index)\n",
    "\n",
    "    # sharpe ratio loss\n",
    "    loss = lossfn(prices_batch, weights_pred, ascent=True)\n",
    "\n",
    "    # compute gradients and backpropagate\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar.set_description(\"Test sharpe (loss): %1.5f\" % (loss.item() * -1))\n",
    "\n",
    "    # store predictions and true values\n",
    "    prices.append(prices_batch)\n",
    "    weights.append(weights_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-popt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
