{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils.dataset_utils import concatenate_prices_returns, create_rolling_window_ts\n",
    "from loss_functions.SharpeLoss import SharpeLoss\n",
    "from models.DLPO import DLPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network hyperparameters\n",
    "input_size = 4 * 2\n",
    "output_size = 4\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "\n",
    "# optimization hyperparameters\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# training hyperparameters\n",
    "device = torch.device('cpu')\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "num_timesteps_in = 50\n",
    "num_timesteps_out = 1\n",
    "train_ratio = 0.7\n",
    "\n",
    "# relevant paths\n",
    "source_path = os.getcwd()\n",
    "inputs_path = os.path.join(source_path, \"data\", \"inputs\")\n",
    "\n",
    "# prepare dataset\n",
    "prices = pd.read_excel(os.path.join(inputs_path, \"etfs-zhang-zohren-roberts.xlsx\"))\n",
    "prices.set_index(\"date\", inplace=True)\n",
    "returns = np.log(prices).diff().dropna()\n",
    "prices = prices.loc[returns.index]\n",
    "features = concatenate_prices_returns(prices=prices, returns=returns)\n",
    "idx = features.index\n",
    "returns = returns.loc[idx].values.astype('float32')\n",
    "prices = prices.loc[idx].values.astype('float32')\n",
    "features = features.loc[idx].values.astype('float32')  \n",
    "\n",
    "X, prices = create_rolling_window_ts(features=features, \n",
    "                                     target=prices,\n",
    "                                     num_timesteps_in=num_timesteps_in,\n",
    "                                     num_timesteps_out=num_timesteps_out)\n",
    "\n",
    "# define train and test datasets\n",
    "train_size = int(prices.shape[0] * train_ratio)\n",
    "X_train, prices_train = X[0:train_size], prices[0:train_size]\n",
    "X_test, prices_test = X[train_size:], prices[train_size:]\n",
    "\n",
    "# define data loaders\n",
    "train_loader = data.DataLoader(data.TensorDataset(X_train, prices_train), shuffle=shuffle, batch_size=batch_size, drop_last=drop_last)\n",
    "test_loader = data.DataLoader(data.TensorDataset(X_test, prices_test), shuffle=False, batch_size=batch_size, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, sharpe (loss): 0.21059: 100%|██████████| 307/307 [00:02<00:00, 149.60it/s]\n",
      "Epoch: 1, sharpe (loss): 0.23540: 100%|██████████| 307/307 [00:01<00:00, 175.03it/s]\n",
      "Epoch: 2, sharpe (loss): 0.17361: 100%|██████████| 307/307 [00:01<00:00, 169.80it/s]\n",
      "Epoch: 3, sharpe (loss): 0.18576: 100%|██████████| 307/307 [00:01<00:00, 175.89it/s]\n",
      "Epoch: 4, sharpe (loss): 0.13040: 100%|██████████| 307/307 [00:02<00:00, 135.39it/s]\n",
      "Epoch: 5, sharpe (loss): 0.10906: 100%|██████████| 307/307 [00:03<00:00, 88.71it/s] \n",
      "Epoch: 6, sharpe (loss): 0.16837: 100%|██████████| 307/307 [00:03<00:00, 84.73it/s] \n",
      "Epoch: 7, sharpe (loss): 0.20554: 100%|██████████| 307/307 [00:03<00:00, 89.33it/s] \n",
      "Epoch: 8, sharpe (loss): 0.18178: 100%|██████████| 307/307 [00:03<00:00, 102.15it/s] \n",
      "Epoch: 9, sharpe (loss): 0.13710: 100%|██████████| 307/307 [00:03<00:00, 83.71it/s] \n",
      "Epoch: 10, sharpe (loss): 0.23579: 100%|██████████| 307/307 [00:03<00:00, 94.80it/s] \n"
     ]
    }
   ],
   "source": [
    "# (1) model\n",
    "model = DLPO(input_size=input_size,\n",
    "             output_size=output_size,\n",
    "             hidden_size=hidden_size,\n",
    "             num_layers=num_layers,\n",
    "             batch_first=True).to(device)\n",
    "\n",
    "# (2) loss fucntion\n",
    "lossfn = SharpeLoss()\n",
    "\n",
    "# (3) optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# (4) training procedure\n",
    "training_loss_values = []\n",
    "model.train()\n",
    "for epoch in range(epochs + 1):\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, (X_batch, prices_batch) in pbar:\n",
    "                \n",
    "        # compute forward propagation\n",
    "        weights_pred = model.forward(X_batch)\n",
    "\n",
    "        # compute loss\n",
    "        loss = lossfn(prices_batch, weights_pred, ascent=True)\n",
    "\n",
    "        # compute gradients and backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pbar.set_description(\"Epoch: %d, sharpe (loss): %1.5f\" % (epoch, loss.item() * -1))\n",
    "        \n",
    "    training_loss_values.append(loss.item() * -1)\n",
    "\n",
    "training_loss_df = pd.DataFrame(training_loss_values, columns=[\"sharpe_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: sharpe (loss): 0.03370: 100%|██████████| 131/131 [00:00<00:00, 148.13it/s] \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Store for analysis\n",
    "weights = []\n",
    "prices = []\n",
    "\n",
    "pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "for i, (X_batch, prices_batch) in pbar:\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute forward propagation\n",
    "    weights_pred = model.forward(X_batch)\n",
    "\n",
    "    # compute loss\n",
    "    loss = lossfn(prices_batch, weights_pred, ascent=True)\n",
    "    \n",
    "    # compute gradients and backpropagate\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_description(\"Test sharpe (loss): %1.5f\" % (loss.item() * -1))\n",
    "\n",
    "    # store predictions and true values\n",
    "    prices.append(prices_batch)\n",
    "    weights.append(weights_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-popt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
