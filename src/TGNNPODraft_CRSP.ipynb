{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from data.CRSPLoader import CRSPLoader\n",
    "from loss_functions.SharpeLoss import SharpeLoss\n",
    "from models.TGNNPO import TGNNPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in saved CRSP data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylansandfelder/Documents/Work/DanielCollab/graph-portfolio-opt/src/data/CRSPLoader.py:27: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  self._load_data(self.load_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CRSP dataset...\n",
      "Generating feature matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5531/5531 [00:08<00:00, 615.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating target matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5531/5531 [00:02<00:00, 1980.32it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "window_length = 50\n",
    "step_length = 5\n",
    "\n",
    "# load and prepare dataset\n",
    "loader = CRSPLoader(load_data=True)\n",
    "etf_tickers = ['SPY', 'XLF', 'XLB', 'XLK', 'XLV']\n",
    "loader._update_ticker_index(ticker_list=etf_tickers)\n",
    "dataset = loader.get_dataset(data=loader.select_tickers(tickers=etf_tickers), window_length=window_length, step_length=step_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization hyperparameters\n",
    "learning_rate = 0.1\n",
    "\n",
    "# how recently should we consider our model to be \"trained\" by?\n",
    "lookback_loss_mean = 200\n",
    "\n",
    "# training hyperparameters\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, sharpe (mean loss): 1.07450: 100%|██████████| 1097/1097 [01:01<00:00, 17.74it/s]\n",
      "Epoch: 1, sharpe (mean loss): 1.13290: 100%|██████████| 1097/1097 [01:02<00:00, 17.65it/s]\n",
      "Epoch: 2, sharpe (mean loss): 1.14830: 100%|██████████| 1097/1097 [01:01<00:00, 17.73it/s]\n",
      "Epoch: 3, sharpe (mean loss): 1.12550: 100%|██████████| 1097/1097 [01:01<00:00, 17.76it/s]\n",
      "Epoch: 4, sharpe (mean loss): 1.14302: 100%|██████████| 1097/1097 [01:01<00:00, 17.81it/s]\n",
      "Epoch: 5, sharpe (mean loss): 1.14293: 100%|██████████| 1097/1097 [01:01<00:00, 17.78it/s]\n",
      "Epoch: 6, sharpe (mean loss): 1.14324: 100%|██████████| 1097/1097 [01:01<00:00, 17.73it/s]\n",
      "Epoch: 7, sharpe (mean loss): 1.13970: 100%|██████████| 1097/1097 [01:01<00:00, 17.71it/s]\n",
      "Epoch: 8, sharpe (mean loss): 1.13970: 100%|██████████| 1097/1097 [01:01<00:00, 17.74it/s]\n",
      "Epoch: 9, sharpe (mean loss): 1.13968: 100%|██████████| 1097/1097 [01:01<00:00, 17.70it/s]\n",
      "Epoch: 10, sharpe (mean loss): 1.13852: 100%|██████████| 1097/1097 [01:01<00:00, 17.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# (1) model\n",
    "model = TGNNPO(node_features=loader.num_features, num_nodes=loader.num_nodes, periods=window_length).to(device)\n",
    "\n",
    "# (2) loss function\n",
    "lossfn = SharpeLoss()\n",
    "\n",
    "# (3) training procedure\n",
    "model.train()\n",
    "for epoch in range(epochs + 1): \n",
    "    # optimizer resets itself between epochs\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=(learning_rate/10.0))\n",
    "    loss_mean = []\n",
    "    pbar = tqdm(enumerate(dataset), total=dataset.get_num_batches())\n",
    "    for steps, batch in pbar:\n",
    "        X_batch = batch.x\n",
    "        prices_batch = batch.y\n",
    "        static_edge_index = batch.edge_index\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict portfolio weights\n",
    "        weights_pred = model(X_batch, static_edge_index)\n",
    "  \n",
    "        # sharpe ratio loss\n",
    "        loss = lossfn(prices_batch, weights_pred, ascent=True)\n",
    "        loss_mean.append(loss.item())\n",
    "        if len(loss_mean) < lookback_loss_mean:\n",
    "            cur_mean = sum(loss_mean) / len(loss_mean)\n",
    "        else:\n",
    "            cur_mean = sum(loss_mean[(-1 * lookback_loss_mean):]) / len(loss_mean[(-1 * lookback_loss_mean):])\n",
    "        pbar.set_description(\"Epoch: %d, sharpe (mean loss): %1.5f\" % (epoch, cur_mean * -1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "    learning_rate = learning_rate / 2.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Store for analysis\n",
    "weights = []\n",
    "prices = []\n",
    "\n",
    "pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "for steps, (X_batch, prices_batch) in pbar:\n",
    "\n",
    "    # predict portfolio weights\n",
    "    weights_pred = model(X_batch, static_edge_index)\n",
    "\n",
    "    # sharpe ratio loss\n",
    "    loss = lossfn(prices_batch, weights_pred, ascent=True)\n",
    "\n",
    "    # compute gradients and backpropagate\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar.set_description(\"Test sharpe (loss): %1.5f\" % (loss.item() * -1))\n",
    "\n",
    "    # store predictions and true values\n",
    "    prices.append(prices_batch)\n",
    "    weights.append(weights_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-popt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
